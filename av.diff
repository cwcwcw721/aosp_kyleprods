diff -ur a/frameworks/av/include/media/stagefright/ColorConverter.h b/frameworks/av/include/media/stagefright/ColorConverter.h
--- a/frameworks/av/include/media/stagefright/ColorConverter.h	2016-02-09 07:51:37.610025648 +0000
+++ b/frameworks/av/include/media/stagefright/ColorConverter.h	2016-02-09 07:57:33.894025648 +0000
@@ -67,6 +67,9 @@
     status_t convertCbYCrY(
             const BitmapParams &src, const BitmapParams &dst);
 
+    status_t convertYCbYCr(
+            const BitmapParams &src, const BitmapParams &dst);
+
     status_t convertYUV420Planar(
             const BitmapParams &src, const BitmapParams &dst);
 
diff -ur a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
--- a/frameworks/av/media/libstagefright/ACodec.cpp	2016-02-09 07:51:37.478025648 +0000
+++ b/frameworks/av/media/libstagefright/ACodec.cpp	2016-02-09 07:57:33.898025648 +0000
@@ -604,11 +604,7 @@
 
     status_t err;
     if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
-        if (mStoreMetaDataInOutputBuffers) {
-            err = allocateOutputMetaDataBuffers();
-        } else {
-            err = allocateOutputBuffersFromNativeWindow();
-        }
+        err = allocateOutputBuffersFromNativeWindow();
     } else {
         OMX_PARAM_PORTDEFINITIONTYPE def;
         InitOMXParams(&def);
@@ -736,11 +732,33 @@
             frameHeight,
             def.format.video.eColorFormat);
 #else
+
+    OMX_COLOR_FORMATTYPE HalColorFormat;
+    status_t omxresuilts;
+    
+    ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: %i", def.format.video.eColorFormat);
+    switch (def.format.video.eColorFormat) {
+        case OMX_COLOR_FormatYCbYCr:
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: OMX_COLOR_FormatYCbYCr (%i) -> (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar);
+            def.format.video.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            omxresuilts = mOMX->setParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+            if (omxresuilts != OK) {
+                ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow setParameter(OMX_IndexParamPortDefinition) ERROR");
+            }
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: OMX_COLOR_FormatYCbYCr (%i) -> (%i) -> HAL_PIXEL_FORMAT_YV12 (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        default:
+            ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow def.format.video.eColorFormat: default(%i) -> HAL_PIXEL_FORMAT_YV12 (%i)", def.format.video.eColorFormat, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+    }
+
     err = native_window_set_buffers_geometry(
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
-            def.format.video.eColorFormat);
+            HalColorFormat);
 #endif
 
     if (err != 0) {
@@ -1963,6 +1981,9 @@
         err = setMinBufferSize(kPortIndexInput, (size_t)maxInputSize);
     } else if (!strcmp("OMX.Nvidia.aac.decoder", mComponentName.c_str())) {
         err = setMinBufferSize(kPortIndexInput, 8192);  // XXX
+    }else if (!strncmp(mComponentName.c_str(), "OMX.brcm.video.h264.hw.decoder", 30)) {
+        ALOGE("PATCH:ACodec:configureCodec:[%s] setMinBufferSize", mComponentName.c_str());
+        setMinBufferSize(kPortIndexInput, (1080 * 720 * 3) / 2);
     }
 
     mBaseOutputFormat = outputFormat;
diff -ur a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
--- a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp	2016-02-09 07:51:37.470025648 +0000
+++ b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp	2016-02-09 07:57:33.902025648 +0000
@@ -44,6 +44,7 @@
     switch (mSrcFormat) {
         case OMX_COLOR_FormatYUV420Planar:
         case OMX_COLOR_FormatCbYCrY:
+        case OMX_COLOR_FormatYCbYCr:
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
@@ -110,6 +111,10 @@
             err = convertCbYCrY(src, dst);
             break;
 
+        case OMX_COLOR_FormatYCbYCr:
+            err = convertYCbYCr(src, dst);
+            break;
+
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
             err = convertQCOMYUV420SemiPlanar(src, dst);
             break;
@@ -159,6 +164,71 @@
 
             signed u_b = u * 517;
             signed u_g = -u * 100;
+            signed v_g = -v * 208;
+            signed v_r = v * 409;
+
+            signed tmp1 = y1 * 298;
+            signed b1 = (tmp1 + u_b) / 256;
+            signed g1 = (tmp1 + v_g + u_g) / 256;
+            signed r1 = (tmp1 + v_r) / 256;
+
+            signed tmp2 = y2 * 298;
+            signed b2 = (tmp2 + u_b) / 256;
+            signed g2 = (tmp2 + v_g + u_g) / 256;
+            signed r2 = (tmp2 + v_r) / 256;
+
+            uint32_t rgb1 =
+                ((kAdjustedClip[r1] >> 3) << 11)
+                | ((kAdjustedClip[g1] >> 2) << 5)
+                | (kAdjustedClip[b1] >> 3);
+
+            uint32_t rgb2 =
+                ((kAdjustedClip[r2] >> 3) << 11)
+                | ((kAdjustedClip[g2] >> 2) << 5)
+                | (kAdjustedClip[b2] >> 3);
+
+            if (x + 1 < src.cropWidth()) {
+                *(uint32_t *)(&dst_ptr[x]) = (rgb2 << 16) | rgb1;
+            } else {
+                dst_ptr[x] = rgb1;
+            }
+        }
+
+        src_ptr += src.mWidth * 2;
+        dst_ptr += dst.mWidth;
+    }
+
+    return OK;
+}
+
+status_t ColorConverter::convertYCbYCr(
+        const BitmapParams &src, const BitmapParams &dst) {
+        ALOGE("PATCH:ColorConverter:convertYCbYCr");
+    // XXX Untested
+
+    uint8_t *kAdjustedClip = initClip();
+
+    if (!((src.mCropLeft & 1) == 0
+        && src.cropWidth() == dst.cropWidth()
+        && src.cropHeight() == dst.cropHeight())) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    uint16_t *dst_ptr = (uint16_t *)dst.mBits
+        + dst.mCropTop * dst.mWidth + dst.mCropLeft;
+
+    const uint8_t *src_ptr = (const uint8_t *)src.mBits
+        + (src.mCropTop * dst.mWidth + src.mCropLeft) * 2;
+
+    for (size_t y = 0; y < src.cropHeight(); ++y) {
+        for (size_t x = 0; x < src.cropWidth(); x += 2) {
+            signed y1 = (signed)src_ptr[2 * x ] - 16;
+            signed y2 = (signed)src_ptr[2 * x + 2] - 16;
+            signed u = (signed)src_ptr[2 * x + 1] - 128;
+            signed v = (signed)src_ptr[2 * x + 3] - 128;
+
+            signed u_b = u * 517;
+            signed u_g = -u * 100;
             signed v_g = -v * 208;
             signed v_r = v * 409;
 
diff -ur a/frameworks/av/media/libstagefright/MPEG4Writer.cpp b/frameworks/av/media/libstagefright/MPEG4Writer.cpp
--- a/frameworks/av/media/libstagefright/MPEG4Writer.cpp	2016-02-09 07:51:37.470025648 +0000
+++ b/frameworks/av/media/libstagefright/MPEG4Writer.cpp	2016-02-09 07:57:33.906025648 +0000
@@ -2298,8 +2298,6 @@
 
         timestampUs -= previousPausedDurationUs;
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            return ERROR_MALFORMED;
         }
 
         if (!mIsAudio) {
@@ -2314,8 +2312,6 @@
             cttsOffsetTimeUs =
                     timestampUs - decodingTimeUs;
             if (WARN_UNLESS(kMaxCttsOffsetTimeUs >= decodingTimeUs - timestampUs, "for %s track", trackName)) {
-                copy->release();
-                return ERROR_MALFORMED;
             }
 
             timestampUs = decodingTimeUs;
@@ -2326,8 +2322,6 @@
             currCttsOffsetTimeTicks =
                     (cttsOffsetTimeUs * mTimeScale + 500000LL) / 1000000LL;
             if (WARN_UNLESS(currCttsOffsetTimeTicks <= 0x0FFFFFFFFLL, "for %s track", trackName)) {
-                copy->release();
-                return ERROR_MALFORMED;
             }
 
             if (mStszTableEntries->count() == 0) {
@@ -2368,8 +2362,6 @@
         }
 
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            return ERROR_MALFORMED;
         }
 
         ALOGV("%s media time stamp: %" PRId64 " and previous paused duration %" PRId64,
@@ -2389,12 +2381,6 @@
         if (currDurationTicks < 0ll) {
             ALOGE("timestampUs %" PRId64 " < lastTimestampUs %" PRId64 " for %s track",
                 timestampUs, lastTimestampUs, trackName);
-            copy->release();
-            err = UNKNOWN_ERROR;
-            mSource->notifyError(err);
-            copy->release();
-            copy = NULL;
-            return err;
         }
 
         // if the duration is different for this sample, see if it is close enough to the previous
@@ -2492,7 +2478,6 @@
     }
 
     if (isTrackMalFormed()) {
-        err = ERROR_MALFORMED;
     }
 
     mOwner->trackProgressStatus(mTrackId, -1, err);
diff -ur a/frameworks/av/media/libstagefright/OMXCodec.cpp b/frameworks/av/media/libstagefright/OMXCodec.cpp
--- a/frameworks/av/media/libstagefright/OMXCodec.cpp	2016-02-09 07:51:37.050025648 +0000
+++ b/frameworks/av/media/libstagefright/OMXCodec.cpp	2016-02-09 07:57:33.910025648 +0000
@@ -1713,6 +1713,12 @@
 #endif
 
         int32_t colorFormat;
+
+        if (!strncmp("OMX.brcm.video.h264.hw.decoder", mComponentName, 30)) {
+            ALOGE("PATCH:OMXCodec:setVideoOutputFormat[%s] colorFormat = %i FOUND BRCM set 19", mComponentName, colorFormat);
+            format.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+        }
+
         if (meta->findInt32(kKeyColorFormat, &colorFormat)
                 && colorFormat != OMX_COLOR_FormatUnused
                 && colorFormat != format.eColorFormat) {
@@ -1725,6 +1731,10 @@
                 if (format.eColorFormat == colorFormat) {
                     break;
                 }
+                if(err == 0x80001005){
+                    ALOGE("PATCH:OMXCodec:setVideoOutputFormat[%s] getParameter(OMX_IndexParamVideoPortFormat) colorFormat(%i) != format.eColorFormat (%i) OMX_ErrorNoMore", mComponentName, colorFormat, format.eColorFormat);
+                    err = OMX_ErrorNoMore;
+                }
             }
             if (format.eColorFormat != colorFormat) {
                 CODEC_LOGE("Color format %d is not supported", colorFormat);
@@ -1755,11 +1765,7 @@
 
 #if 1
     // XXX Need a (much) better heuristic to compute input buffer sizes.
-#ifdef USE_SAMSUNG_COLORFORMAT
     const size_t X = 64 * 8 * 1024;
-#else
-    const size_t X = 64 * 1024;
-#endif
     if (def.nBufferSize < X) {
         def.nBufferSize = X;
     }
@@ -2299,11 +2305,37 @@
             frameHeight,
             def.format.video.eColorFormat);
 #else
+
+    ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow def.format.video.eColorFormat = %i", def.format.video.eColorFormat);
+
+    OMX_COLOR_FORMATTYPE HalColorFormat;
+    status_t errss;
+    
+    switch (def.format.video.eColorFormat) {
+        case OMX_COLOR_FormatYCbYCr:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow OMX_COLOR_FormatYCbYCr(%i) -> (%i)", OMX_COLOR_FormatYCbYCr, OMX_COLOR_FormatYUV420Planar);
+            def.format.video.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            errss = mOMX->setParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+            if (errss != OK){
+                ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow setParameter failed: %d", errss);
+            }
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        case OMX_COLOR_FormatYUV420Planar:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow OMX_COLOR_FormatYUV420Planar(%i) -> HAL_PIXEL_FORMAT_YV12(%i)", OMX_COLOR_FormatYUV420Planar, (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12);
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        default:
+            ALOGE("PATCH:OMXCodec:allocateOutputBuffersFromNativeWindow default(%i) -> default(%i)", def.format.video.eColorFormat, def.format.video.eColorFormat);
+            HalColorFormat = def.format.video.eColorFormat;
+        break;
+    }
+
     err = native_window_set_buffers_geometry(
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
-            def.format.video.eColorFormat);
+            HalColorFormat);
 #endif
 
     if (err != 0) {
@@ -5470,7 +5502,13 @@
                     caps->mColorFormats.push(flexibleEquivalent);
                 }
             }
-            caps->mColorFormats.push(portFormat.eColorFormat);
+            if(portFormat.eColorFormat == OMX_COLOR_FormatYCbYCr) {
+                ALOGE("PATCH:OMXCodec:QueryCodec:getParameter(IndexParamVideoPortFormat) portFormat.eColorFormat %i SET %i", portFormat.eColorFormat, OMX_COLOR_FormatYUV420Planar);
+                caps->mColorFormats.push(OMX_COLOR_FormatYUV420Planar);
+            }else{
+                ALOGE("PATCH:OMXCodec:QueryCodec:getParameter(IndexParamVideoPortFormat) DEFAULT portFormat.eColorFormat %i", portFormat.eColorFormat);
+                caps->mColorFormats.push(portFormat.eColorFormat);
+            }
         }
     }
 
